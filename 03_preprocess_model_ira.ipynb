{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./resources/GA.png\" width=\"25\" height=\"25\" />   <span style=\"color:Purple\">Project 5 :  Food Insecurity Regression Study</span> \n",
    "---\n",
    "## <span style=\"color:Green\">Preprocessing / Modeling</span>      \n",
    "\n",
    "#### Alec Edgecliffe-Johnson, Ryan McDonald, Andrew Roberts, Ira Seidman - General Assembly \n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Contents:\n",
    "\n",
    "- [Reading the Data](#intro)\n",
    "- [Modeling](#modeling)\n",
    "    - [Production Model, LinReg](#prod)\n",
    "         - [Extended Analysis](#analysis)\n",
    "    - [Model #2, KNN](#second)\n",
    "    - [Model #3, Decision Tree](#third)\n",
    "    - [Model #4, PolyFeat, LinReg](#fourth)\n",
    "    - [Model #5, ADA Boost](#fifth)\n",
    "    - [Model #6, SVM](#sixth)\n",
    "    - [Model #7, TensorFlow NN](#seventh)\n",
    "    - [Model #8, RandomForest](#eigth)\n",
    "    - [Model #9, PCA, LinRe](#ninth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SciKit Learn Processing/ Modeling Imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Tensor Flow, Keras NN\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## 1. Read the Data\n",
    "Read in data for each of the different imputation files - mean, median, mode, knn, lr, and rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = pd.read_csv('cleaned_dataframes/df_m_mean.csv')\n",
    "df_median = pd.read_csv('cleaned_dataframes/df_m_median.csv')\n",
    "df_mode = pd.read_csv('cleaned_dataframes/df_m_mode.csv')\n",
    "df_knn = pd.read_csv('cleaned_dataframes/df_m_knn.csv')\n",
    "df_lr = pd.read_csv('cleaned_dataframes/df_m_lr.csv')\n",
    "df_rf = pd.read_csv('cleaned_dataframes/df_m_rf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='modeling'></a>\n",
    "## Modeling Pre-work\n",
    "\n",
    "**Setting X, y and Train-Test-Split for each imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['ch_fi_rate_18', 'fi_rate_18', 'cpm_18', 'state_abr', 'state_name', 'fips', 'county']\n",
    "dummified_features_to_drop = ['ch_fi_rate_18', 'fi_rate_18', 'cpm_18',  'fips']\n",
    "\n",
    "# Also drop all the dummy variables from the 'state_abr', 'state_name', and 'county' columns in df_knn, df_lr, and df_rf \n",
    "for col in df_lr.columns:\n",
    "    #print(col)\n",
    "    if (col.startswith(\"state_abr\") or col.startswith(\"state_name\") or col.startswith(\"county\")):\n",
    "        dummified_features_to_drop.append(col)\n",
    "\n",
    "# Set X and y for each imputation\n",
    "X_mean, X_median, X_mode, X_knn, X_lr, X_rf = df_mean.drop(features_to_drop, axis = 1), df_median.drop(features_to_drop, axis = 1), df_mode.drop(features_to_drop, axis = 1), df_knn.drop(dummified_features_to_drop, axis = 1), df_lr.drop(dummified_features_to_drop, axis = 1), df_rf.drop(dummified_features_to_drop, axis = 1)\n",
    "y_mean, y_median, y_mode, y_knn, y_lr, y_rf = df_mean['fi_rate_18'], df_median['fi_rate_18'], df_mode['fi_rate_18'], df_knn['fi_rate_18'], df_lr['fi_rate_18'], df_rf['fi_rate_18']\n",
    "\n",
    "# Train-test splits\n",
    "X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(X_mean, y_mean, random_state = 1)\n",
    "X_train_median, X_test_median, y_train_median, y_test_median = train_test_split(X_median, y_median, random_state = 1)\n",
    "X_train_mode, X_test_mode, y_train_mode, y_test_mode = train_test_split(X_mode, y_mode, random_state = 1)\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_knn, y_knn, random_state = 1)\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_lr, y_lr, random_state = 1)\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for each imptation\n",
    "ss = StandardScaler()\n",
    "\n",
    "Z_train_mean, Z_train_median, Z_train_mode, Z_train_knn, Z_train_lr, Z_train_rf = ss.fit_transform(X_train_mean), ss.fit_transform(X_train_median), ss.fit_transform(X_train_mode), ss.fit_transform(X_train_knn), ss.fit_transform(X_train_lr), ss.fit_transform(X_train_rf)\n",
    "Z_test_mean, Z_test_median, Z_test_mode, Z_test_knn, Z_test_lr, Z_test_rf = ss.transform(X_test_mean), ss.transform(X_test_median), ss.transform(X_test_mode), ss.transform(X_test_knn), ss.transform(X_test_lr), ss.transform(X_test_rf)\n",
    "\n",
    "y_trains = [y_mean, y_median, y_mode, y_knn, y_lr, y_rf]\n",
    "Z_trains = [Z_train_mean, Z_train_median, Z_train_mode, Z_train_knn, Z_train_lr, Z_train_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prod'></a>\n",
    "### Model 1: Production Model\n",
    "\n",
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copy_X', 'fit_intercept', 'n_jobs', 'normalize'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gs_lr_mean</th>\n",
       "      <th>gs_lr_median</th>\n",
       "      <th>gs_lr_mode</th>\n",
       "      <th>gs_lr_knn</th>\n",
       "      <th>gs_lr_lr</th>\n",
       "      <th>gs_lr_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932081</td>\n",
       "      <td>0.932271</td>\n",
       "      <td>0.931995</td>\n",
       "      <td>0.935029</td>\n",
       "      <td>-474.216</td>\n",
       "      <td>0.935189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "      <td>{'lr__copy_X': False, 'lr__fit_intercept': Tru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          gs_lr_mean  \\\n",
       "0                                           0.932081   \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...   \n",
       "\n",
       "                                        gs_lr_median  \\\n",
       "0                                           0.932271   \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...   \n",
       "\n",
       "                                          gs_lr_mode  \\\n",
       "0                                           0.931995   \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...   \n",
       "\n",
       "                                           gs_lr_knn  \\\n",
       "0                                           0.935029   \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...   \n",
       "\n",
       "                                            gs_lr_lr  \\\n",
       "0                                           -474.216   \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...   \n",
       "\n",
       "                                            gs_lr_rf  \n",
       "0                                           0.935189  \n",
       "1  {'lr__copy_X': False, 'lr__fit_intercept': Tru...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_lr = Pipeline([\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Gridsearch over the same parameters for all imputation pipes\n",
    "pipe_ln_params = {'lr__fit_intercept': [False, True],\n",
    "                  'lr__copy_X': [False, True],\n",
    "                  'lr__normalize': [False, True]\n",
    "}\n",
    "\n",
    "pipe_lr_mean, pipe_lr_median, pipe_lr_mode, pipe_lr_knn, pipe_lr_lr, pipe_lr_rf = pipe_lr.fit(Z_train_mean, y_train_mean), pipe_lr.fit(Z_train_median, y_train_median), pipe_lr.fit(Z_train_mode, y_train_mode), pipe_lr.fit(Z_train_knn, y_train_knn), pipe_lr.fit(Z_train_lr, y_train_lr), pipe_lr.fit(Z_train_rf, y_train_rf)\n",
    "\n",
    "#Gridsearch on pipes for different imputations\n",
    "gs_lr_mean = GridSearchCV(pipe_lr_mean,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "gs_lr_median = GridSearchCV(pipe_lr_median,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "gs_lr_mode = GridSearchCV(pipe_lr_mode,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "gs_lr_knn = GridSearchCV(pipe_lr_knn,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "gs_lr_lr = GridSearchCV(pipe_lr_lr,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "gs_lr_rf = GridSearchCV(pipe_lr_rf,\n",
    "                     param_grid = pipe_ln_params,\n",
    "                     cv = 5)\n",
    "\n",
    "gs_lr_mean.fit(Z_train_mean, y_train_mean), gs_lr_median.fit(Z_train_median, y_train_median), gs_lr_mode.fit(Z_train_mode, y_train_mode), gs_lr_knn.fit(Z_train_knn, y_train_knn), gs_lr_lr.fit(Z_train_lr, y_train_lr), gs_lr_rf.fit(Z_train_rf, y_train_rf)\n",
    "\n",
    "# Return best scores and params for cross-validated pipes\n",
    "lr_pipes = {'gs_lr_mean': [gs_lr_mean.best_score_, gs_lr_mean.best_params_],\n",
    "            'gs_lr_median': [gs_lr_median.best_score_, gs_lr_median.best_params_],\n",
    "            'gs_lr_mode': [gs_lr_mode.best_score_, gs_lr_mode.best_params_],\n",
    "            'gs_lr_knn': [gs_lr_knn.best_score_, gs_lr_knn.best_params_],\n",
    "            'gs_lr_lr': [gs_lr_lr. , gs_lr_lr.best_params_],\n",
    "            'gs_lr_rf': [gs_lr_rf.best_score_, gs_lr_rf.best_params_]\n",
    "           }\n",
    "\n",
    "gs_lr_results = pd.DataFrame(lr_pipes)\n",
    "gs_lr_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training RMSE</th>\n",
       "      <th>Testing RMSE</th>\n",
       "      <th>Training R2</th>\n",
       "      <th>Testing R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gs_lr_mean training score:</th>\n",
       "      <td>0.944634</td>\n",
       "      <td>0.944203</td>\n",
       "      <td>0.940169</td>\n",
       "      <td>0.934663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_lr_median training score:</th>\n",
       "      <td>3.718488</td>\n",
       "      <td>0.940585</td>\n",
       "      <td>0.940152</td>\n",
       "      <td>0.934755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_lr_mode training score:</th>\n",
       "      <td>0.945299</td>\n",
       "      <td>0.951658</td>\n",
       "      <td>0.939697</td>\n",
       "      <td>0.934314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_lr_knn training score:</th>\n",
       "      <td>0.925629</td>\n",
       "      <td>0.946216</td>\n",
       "      <td>0.940283</td>\n",
       "      <td>0.935370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_lr_lr training score:</th>\n",
       "      <td>3.718518</td>\n",
       "      <td>20307.330799</td>\n",
       "      <td>-30405.095115</td>\n",
       "      <td>-32576.614223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gs_lr_rf training score:</th>\n",
       "      <td>0.925988</td>\n",
       "      <td>0.933373</td>\n",
       "      <td>0.940360</td>\n",
       "      <td>0.935316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Training RMSE  Testing RMSE   Training R2  \\\n",
       "gs_lr_mean training score:          0.944634      0.944203      0.940169   \n",
       "gs_lr_median training score:        3.718488      0.940585      0.940152   \n",
       "gs_lr_mode training score:          0.945299      0.951658      0.939697   \n",
       "gs_lr_knn training score:           0.925629      0.946216      0.940283   \n",
       "gs_lr_lr training score:            3.718518  20307.330799 -30405.095115   \n",
       "gs_lr_rf training score:            0.925988      0.933373      0.940360   \n",
       "\n",
       "                                 Testing R2  \n",
       "gs_lr_mean training score:         0.934663  \n",
       "gs_lr_median training score:       0.934755  \n",
       "gs_lr_mode training score:         0.934314  \n",
       "gs_lr_knn training score:          0.935370  \n",
       "gs_lr_lr training score:      -32576.614223  \n",
       "gs_lr_rf training score:           0.935316  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mean_preds_train, lr_median_preds_train, lr_mode_preds_train, lr_knn_preds_train, lr_lr_preds_train, lr_rf_preds_train = gs_lr_mean.predict(Z_train_mean), gs_lr_median.predict(Z_train_median), gs_lr_mode.predict(Z_train_mode), gs_lr_knn.predict(Z_train_knn), gs_lr_lr.predict(Z_train_lr), gs_lr_rf.predict(Z_train_rf)\n",
    "lr_mean_preds_test, lr_median_preds_test, lr_mode_preds_test, lr_knn_preds_test, lr_lr_preds_test, lr_rf_preds_test = gs_lr_mean.predict(Z_test_mean), gs_lr_median.predict(Z_test_median), gs_lr_mode.predict(Z_test_mode), gs_lr_knn.predict(Z_test_knn), gs_lr_lr.predict(Z_test_lr), gs_lr_rf.predict(Z_test_rf)\n",
    "\n",
    "# Return best scores and params for predictions based off of training data\n",
    "lr_mse_results = {'gs_lr_mean training score: ' : [mean_squared_error(y_train_mean, lr_mean_preds_train, squared = False), mean_squared_error(y_test_mean, lr_mean_preds_test, squared = False), gs_lr_mean.score(Z_train_rf, y_train_rf), gs_lr_mean.score(Z_test_rf, y_test_rf)],\n",
    "                  'gs_lr_median training score: ' : [mean_squared_error(y_train_median, lr_median_preds_train, squared = False), mean_squared_error(y_test_median, lr_median_preds_test, squared = False), gs_lr_median.score(Z_train_rf, y_train_rf), gs_lr_median.score(Z_test_rf, y_test_rf)],\n",
    "                  'gs_lr_mode training score: ' : [mean_squared_error(y_train_mode, lr_mode_preds_train, squared = False), mean_squared_error(y_test_mode, lr_mode_preds_test, squared = False), gs_lr_mode.score(Z_train_rf, y_train_rf), gs_lr_mode.score(Z_test_rf, y_test_rf)],\n",
    "                  'gs_lr_knn training score: ' : [mean_squared_error(y_train_knn, lr_knn_preds_train, squared = False), mean_squared_error(y_test_knn, lr_knn_preds_test, squared = False), gs_lr_knn.score(Z_train_rf, y_train_rf), gs_lr_knn.score(Z_test_rf, y_test_rf)],\n",
    "                  'gs_lr_lr training score: ' : [mean_squared_error(y_train_lr, lr_lr_preds_train, squared = False), mean_squared_error(y_test_lr, lr_lr_preds_test, squared = False), gs_lr_lr.score(Z_train_rf, y_train_rf), gs_lr_lr.score(Z_test_rf, y_test_rf)],\n",
    "                  'gs_lr_rf training score: ' : [mean_squared_error(y_train_rf, lr_rf_preds_train, squared = False), mean_squared_error(y_test_rf, lr_rf_preds_test, squared = False), gs_lr_rf.score(Z_train_rf, y_train_rf), gs_lr_rf.score(Z_test_rf, y_test_rf)]\n",
    "                  }\n",
    "\n",
    "lr_mse_results = pd.DataFrame(lr_mse_results, index = ['Training RMSE', 'Testing RMSE', 'Training R2', 'Testing R2']).T\n",
    "lr_mse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>percent_disabled</td>\n",
       "      <td>0.844686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>percent_children_in_poverty</td>\n",
       "      <td>0.564253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>percent_fair_or_poor_health</td>\n",
       "      <td>0.367634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>percent_severe_housing_cost_burden</td>\n",
       "      <td>0.330053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percent_below_poverty</td>\n",
       "      <td>0.229229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>percent_single_parent_households_CHR</td>\n",
       "      <td>0.174989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>percent_severe_housing_problems</td>\n",
       "      <td>0.174969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_households_CHR</td>\n",
       "      <td>0.157639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average_number_of_mentally_unhealthy_days</td>\n",
       "      <td>0.148209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>percent_unemployed_CDC</td>\n",
       "      <td>0.146774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     features  coefficients\n",
       "44                           percent_disabled      0.844686\n",
       "16                percent_children_in_poverty      0.564253\n",
       "5                 percent_fair_or_poor_health      0.367634\n",
       "28         percent_severe_housing_cost_burden      0.330053\n",
       "39                      percent_below_poverty      0.229229\n",
       "18       percent_single_parent_households_CHR      0.174989\n",
       "20            percent_severe_housing_problems      0.174969\n",
       "17                         num_households_CHR      0.157639\n",
       "6   average_number_of_mentally_unhealthy_days      0.148209\n",
       "40                     percent_unemployed_CDC      0.146774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinstantiate pipe_lr with gridsearched parameters\n",
    "pipe_lr = Pipeline([\n",
    "    ('lr', LinearRegression(copy_X = False, fit_intercept = True, normalize = False))\n",
    "])\n",
    "pipe_lr = pipe_lr.fit(Z_train_mean, y_train_mean) \n",
    "\n",
    "# Show ten strongest features for best testing model - random forest imputation\n",
    "coefs_lr = pipe_lr.named_steps['lr'].coef_.flatten()\n",
    "feature_names_dummified = list(X_train_rf.columns) #list of features to use when outputting feature weights\n",
    "\n",
    "model_zip = zip(feature_names_dummified, coefs_lr)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model fit was the linear regression using the random forest imputation data. Below are all the additional models fit, but none beat a testing RMSE of .9334 that weren't tremendously computationally intensive. This model may be slightly underfit, but not enough to try and introduce more variance with more data/columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='second'></a>\n",
    "### Model 2: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['algorithm', 'leaf_size', 'metric', 'metric_params', 'n_jobs', 'n_neighbors', 'p', 'weights'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsRegressor().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_knn = Pipeline([\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "pipe_knn_params = {'knn__n_neighbors': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "                  }\n",
    "\n",
    "pipe_knn.fit(Z_train_rf, y_train_rf)\n",
    "\n",
    "gs_knn = GridSearchCV(pipe_knn, \n",
    "                        param_grid = pipe_knn_params, \n",
    "                        cv = 5)\n",
    "\n",
    "gs_knn.fit(Z_train_rf, y_train_rf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8564094905787188\n",
      "Best parameters: {'knn__n_neighbors': 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {gs_knn.best_score_}')\n",
    "print(f'Best parameters: {gs_knn.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn Training RMSE: 1.1507743538974573\n",
      "Knn Testing RMSE: 1.471999376903773\n",
      "Training R2: 0.9078905752959054\n",
      "Testing R2: 0.8391212017356469\n"
     ]
    }
   ],
   "source": [
    "knn_preds_train = gs_knn.predict(Z_train_rf)\n",
    "knn_preds_test = gs_knn.predict(Z_test_rf)\n",
    "\n",
    "print(f'Knn Training RMSE: {mean_squared_error(y_train_rf, knn_preds_train, squared = False)}')\n",
    "print(f'Knn Testing RMSE: {mean_squared_error(y_test_rf, knn_preds_test, squared = False)}')\n",
    "print(f'Training R2: {pipe_knn.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Testing R2: {pipe_knn.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any value of k. This model could be better fit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='third'></a>\n",
    "### Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'presort', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeRegressor().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeRegressor().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('dt', DecisionTreeRegressor())]),\n",
       "             param_grid={'dt__max_depth': [2, 4, 6, 8, 10, 12],\n",
       "                         'dt__max_features': ['auto', 'log2']})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_dt = Pipeline([\n",
    "    ('dt', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "pipe_dt_params = {'dt__max_depth': [5, 10, None], \n",
    "                  'dt__max_features': ['auto', 'log2'], \n",
    "                  'dt__max_depth': [2,4,6,8,10,12]\n",
    "                 }\n",
    "\n",
    "pipe_dt.fit(Z_train_rf, y_train_rf)\n",
    "gs_dt = GridSearchCV(pipe_dt, \n",
    "                     param_grid = pipe_dt_params,\n",
    "                     cv = 5)\n",
    "\n",
    "gs_dt.fit(Z_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.797309452865617\n",
      "Best parameters: {'dt__max_depth': 6, 'dt__max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {gs_dt.best_score_}')\n",
    "print(f'Best parameters: {gs_dt.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dt training RMSE: 1.1507743538974573\n",
      "Dt testing RMSE: 1.471999376903773\n",
      "Dt training R2: 1.0\n",
      "Dt testing R2: 0.7657571918524686\n"
     ]
    }
   ],
   "source": [
    "dt_preds_train = gs_dt.predict(Z_train_rf)\n",
    "dt_preds_test = gs_dt.predict(Z_test_rf)\n",
    "\n",
    "print(f'Dt training RMSE: {mean_squared_error(y_train_rf, knn_preds_train, squared = False)}')\n",
    "print(f'Dt testing RMSE: {mean_squared_error(y_test_rf, knn_preds_test, squared = False)}')\n",
    "print(f'Dt training R2: {pipe_dt.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Dt testing R2: {pipe_dt.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any combination of hyperparameters. This model is very overfit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fourth'></a>\n",
    "### Model 4: PolynomialFeatures with StandardScalar and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = ['percent_children_in_poverty', 'percent_below_poverty', 'percent_fair_or_poor_health',\n",
    "                 'pct_overall_pov_19','percentile_rank_social_vulnerability']\n",
    "\n",
    "X_rf = df_rf[poly_features]\n",
    "y_rf = df_rf['fi_rate_18']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rf,\n",
    "                                                    y_rf,\n",
    "                                                    random_state = 1)\n",
    "pf = PolynomialFeatures(degree = 2)\n",
    "X_train_pf = pf.fit_transform(X_train)\n",
    "X_test_pf = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['copy_X', 'fit_intercept', 'n_jobs', 'normalize']),\n",
       " dict_keys(['degree', 'include_bias', 'interaction_only', 'order']))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression().get_params().keys(), PolynomialFeatures().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('lr', LinearRegression())]),\n",
       "             param_grid={'lr__fit_intercept': [True, False],\n",
       "                         'lr__normalize': [True, False]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_poly_lr = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LinearRegression()),\n",
    "])\n",
    "\n",
    "pipe_poly_lr_params = {'lr__normalize': [True, False],\n",
    "                       'lr__fit_intercept': [True, False]\n",
    "                  }\n",
    "\n",
    "pipe_poly_lr.fit(X_train_pf, y_train)\n",
    "gs_poly_lr = GridSearchCV(pipe_poly_lr, \n",
    "                        param_grid = pipe_poly_lr_params, \n",
    "                        cv = 5)\n",
    "\n",
    "gs_poly_lr.fit(X_train_pf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8074070574459841\n",
      "Best parameters: {'lr__fit_intercept': True, 'lr__normalize': True}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {gs_poly_lr.best_score_}')\n",
    "print(f'Best parameters: {gs_poly_lr.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly lr Training RMSE: 1.6383377507745998\n",
      "Poly lr Testing RMSE: 1.7307918859845965\n",
      "Poly lr Training R2: 0.8133058982899347\n",
      "Poly lr Testing R2: 0.7775802940495057\n"
     ]
    }
   ],
   "source": [
    "# Reinstantiate pipe_poly_lr with gridsearched parameters\n",
    "pipe_poly_lr = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('lr', LinearRegression(fit_intercept = True, normalize = True))\n",
    "])\n",
    "pipe_poly_lr = pipe_lr.fit(Z_train_mean, y_train_mean) \n",
    "\n",
    "lr_poly_preds_train = gs_poly_lr.predict(X_train_pf)\n",
    "lr_poly_preds_test = gs_poly_lr.predict(X_test_pf)\n",
    "\n",
    "print(f'Poly lr Training RMSE: {mean_squared_error(y_train, lr_poly_preds_train, squared = False)}')\n",
    "print(f'Poly lr Testing RMSE: {mean_squared_error(y_test, lr_poly_preds_test, squared = False)}')\n",
    "print(f'Poly lr Training R2: {gs_poly_lr.score(X_train_pf, y_train)}')\n",
    "print(f'Poly lr Testing R2: {gs_poly_lr.score(X_test_pf, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>percent_disabled</td>\n",
       "      <td>0.844686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>percent_children_in_poverty</td>\n",
       "      <td>0.564253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>percent_fair_or_poor_health</td>\n",
       "      <td>0.367634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>percent_severe_housing_cost_burden</td>\n",
       "      <td>0.330053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percent_below_poverty</td>\n",
       "      <td>0.229229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>percent_single_parent_households_CHR</td>\n",
       "      <td>0.174989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>percent_severe_housing_problems</td>\n",
       "      <td>0.174969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_households_CHR</td>\n",
       "      <td>0.157639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average_number_of_mentally_unhealthy_days</td>\n",
       "      <td>0.148209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>percent_unemployed_CDC</td>\n",
       "      <td>0.146774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     features  coefficients\n",
       "44                           percent_disabled      0.844686\n",
       "16                percent_children_in_poverty      0.564253\n",
       "5                 percent_fair_or_poor_health      0.367634\n",
       "28         percent_severe_housing_cost_burden      0.330053\n",
       "39                      percent_below_poverty      0.229229\n",
       "18       percent_single_parent_households_CHR      0.174989\n",
       "20            percent_severe_housing_problems      0.174969\n",
       "17                         num_households_CHR      0.157639\n",
       "6   average_number_of_mentally_unhealthy_days      0.148209\n",
       "40                     percent_unemployed_CDC      0.146774"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show ten strongest features for best testing model\n",
    "coefs_lr_poly = pipe_poly_lr.named_steps['lr'].coef_.flatten()\n",
    "model_zip = zip(feature_names_dummified, coefs_lr_poly)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Will Lasso Improve our Score?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(max_iter=15000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(max_iter = 15000 )\n",
    "lasso.fit(X_train_pf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso CV Training RMSE: 1.8290381142003298\n",
      "Lasso CV Training RMSE: 1.8633380988879227\n",
      "Lasso CV Training R2: 0.7673145477251163\n",
      "Lasso CV Testing R2: 0.7422095118120987\n"
     ]
    }
   ],
   "source": [
    "lasso_preds_train = lasso.predict(X_train_pf)\n",
    "lasso_preds_test = lasso.predict(X_test_pf)\n",
    "\n",
    "print(f'Lasso CV Training RMSE: {mean_squared_error(y_train, lasso_preds_train, squared = False)}')\n",
    "print(f'Lasso CV Training RMSE: {mean_squared_error(y_test, lasso_preds_test, squared = False)}')\n",
    "print(f\"Lasso CV Training R2: {lasso.score(X_train_pf, y_train)}\")\n",
    "print(f\"Lasso CV Testing R2: {lasso.score(X_test_pf, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any combination of hyperparameters with poly features. No improvement with lasso and though this model is very overfit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fifth'></a>\n",
    "### Model 5: ADA Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Feature and Target Variables\n",
    "**Scaling and Train-Test-Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_estimator', 'learning_rate', 'loss', 'n_estimators', 'random_state'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "AdaBoostRegressor().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('ada', AdaBoostRegressor())]),\n",
       "             param_grid={'ada__learning_rate': [1, 5, 10],\n",
       "                         'ada__loss': ['linear', 'square', 'exponential'],\n",
       "                         'ada__n_estimators': [100, 150, 200]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_ada = Pipeline([\n",
    "    ('ada', AdaBoostRegressor())\n",
    "])\n",
    "\n",
    "# Credit from subscription.packtub - https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781787286382/9/ch09lvl1sec95/tuning-an-adaboost-regressor\n",
    "pipe_ada_params = {\n",
    "    'ada__n_estimators': [100, 150, 200],\n",
    "    'ada__learning_rate' : [1, 5, 10],\n",
    "    'ada__loss' : ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "pipe_ada.fit(Z_train_rf, y_train_rf)\n",
    "gs_ada = GridSearchCV(pipe_ada, \n",
    "                        param_grid = pipe_ada_params, \n",
    "                        cv = 5)\n",
    "\n",
    "gs_ada.fit(Z_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.870771561472685\n",
      "Best parameters: {'ada__learning_rate': 5, 'ada__loss': 'exponential', 'ada__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best score: {gs_ada.best_score_}')\n",
    "print(f'Best parameters: {gs_ada.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Training RMSE: 1.2595210458115744\n",
      "AdaBoost Testing RMSE: 1.455008375899492\n",
      "Training R2: 0.8867648066871314\n",
      "Testing R2: 0.8353152053922577\n"
     ]
    }
   ],
   "source": [
    "# Reinstantiate pipe_ada with gridsearched parameters\n",
    "pipe_ada = Pipeline([\n",
    "    ('ada', AdaBoostRegressor(learning_rate = 5, loss = 'exponential', n_estimators = 150))\n",
    "])\n",
    "pipe_ada = pipe_ada.fit(Z_train_mean, y_train_mean)\n",
    "\n",
    "ada_preds_train = gs_ada.predict(Z_train_rf)\n",
    "ada_preds_test = gs_ada.predict(Z_test_rf)\n",
    "\n",
    "print(f'AdaBoost Training RMSE: {mean_squared_error(y_train_rf, ada_preds_train, squared = False)}')\n",
    "print(f'AdaBoost Testing RMSE: {mean_squared_error(y_test_rf, ada_preds_test, squared = False)}')\n",
    "print(f'Training R2: {pipe_ada.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Testing R2: {pipe_ada.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percent_below_poverty</td>\n",
       "      <td>0.192617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>percent_children_in_poverty</td>\n",
       "      <td>0.138434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>average_number_of_mentally_unhealthy_days</td>\n",
       "      <td>0.078175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>percentile_rank_social_vulnerability</td>\n",
       "      <td>0.075379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>life_expectancy</td>\n",
       "      <td>0.063503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>pct_overall_pov_19</td>\n",
       "      <td>0.061981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>median_household_income</td>\n",
       "      <td>0.056408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>percent_disabled</td>\n",
       "      <td>0.050518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>percent_unemployed_CDC</td>\n",
       "      <td>0.036529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>percent_fair_or_poor_health</td>\n",
       "      <td>0.034874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     features  coefficients\n",
       "39                      percent_below_poverty      0.192617\n",
       "16                percent_children_in_poverty      0.138434\n",
       "6   average_number_of_mentally_unhealthy_days      0.078175\n",
       "47       percentile_rank_social_vulnerability      0.075379\n",
       "22                            life_expectancy      0.063503\n",
       "48                         pct_overall_pov_19      0.061981\n",
       "25                    median_household_income      0.056408\n",
       "44                           percent_disabled      0.050518\n",
       "40                     percent_unemployed_CDC      0.036529\n",
       "5                 percent_fair_or_poor_health      0.034874"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show ten strongest features for best testing model\n",
    "coefs_ada = pipe_ada.named_steps['ada'].feature_importances_\n",
    "model_zip = zip(feature_names_dummified, coefs_ada)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any combination of hyperparameters. This model is again overfit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sixth'></a>\n",
    "### Model 6: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_svr = Pipeline([\n",
    "    ('svr', SVR(kernel = 'linear'))\n",
    "])\n",
    "\n",
    "\n",
    "pipe_svr_params = {\n",
    "    'svr__C': [.01, .1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "\n",
    "pipe_svr.fit(Z_train_rf, y_train_rf)\n",
    "gs_svr = GridSearchCV(pipe_svr,\n",
    "                      param_grid = pipe_svr_params,\n",
    "                      cv = 5,\n",
    "                      n_jobs = 4\n",
    ")\n",
    "\n",
    "gs_svr.fit(Z_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best score: {gs_svr.best_score_}')\n",
    "print(f'Best parameters: {gs_svr.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstantiate pipe_svr with gridsearched parameters\n",
    "pipe_svr = Pipeline([\n",
    "    ('svr', SVR(kernel = 'linear', C = 100))\n",
    "])\n",
    "pipe_svr = pipe_svr.fit(Z_train_mean, y_train_mean)\n",
    "\n",
    "svr_preds_train = gs_svr.predict(Z_train_rf)\n",
    "svr_preds_test = gs_svr.predict(Z_test_rf)\n",
    "\n",
    "print(f'SVR Training RMSE: {mean_squared_error(y_train, svr_preds_train, squared = False)}')\n",
    "print(f'SVR Testing RMSE: {mean_squared_error(y_test, svr_preds_test, squared = False)}')\n",
    "print(f'Training R2: {pipe_svr.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Testing R2: {pipe_svr.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ten strongest features for best testing model - attribute error associated with coefficents. Cannot get coefficents, but since we are seeking accuracy over interpretability then that is OK.\n",
    "coefs_svr = pipe_svr.named_steps['svr'].coef_.flatten()\n",
    "model_zip = zip(feature_names_dummified, coefs_svr)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does beat linear regression by about .015 on RMSE and is well fit, but given the computational requirements associated with this model it was not chosen as the production model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='seventh'></a>\n",
    "### Model 7: TensorFlow NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = RootMeanSquaredError()\n",
    "\n",
    "# Set up nn\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_shape = (Z_train_rf.shape[1],),\n",
    "                activation = 'relu',\n",
    "               ))\n",
    "\n",
    "model.add(BatchNormalization()) # BatchNormalization layer added from Part 7\n",
    "\n",
    "model.add(Dense(128, activation = 'relu',\n",
    "                kernel_regularizer = l2(0.01)\n",
    "               )) # Second hidden layer\n",
    "\n",
    "model.add(Dropout(0.05)) # Dropout layer 5 % to 2nd layer\n",
    "\n",
    "model.add(Dense(64, activation = 'relu', \n",
    "                kernel_regularizer = l2(0.1)\n",
    "               )) # Third hidden layer\n",
    "\n",
    "model.add(Dropout(0.20)) # Dropout layer 20 % to 3rd layer\n",
    "\n",
    "# Add output layer\n",
    "\n",
    "model.add(Dense(1, activation = None)) \n",
    "\n",
    "# Compile\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics= [rmse,'mse'])                                     \n",
    "\n",
    "# Early_stop object\n",
    "early_stop = EarlyStopping(patience = 5)\n",
    "\n",
    "# Fit\n",
    "results_es = model.fit(Z_train_rf, y_train_rf,\n",
    "            validation_data = (Z_test_rf, y_test_rf),\n",
    "            epochs = 50, \n",
    "            verbose = 0,\n",
    "            callbacks = [early_stop])\n",
    "\n",
    "# Visualize loss\n",
    "train_loss = results_es.history['loss']\n",
    "test_loss = results_es.history['val_loss']\n",
    "train_rmse = results_es.history['root_mean_squared_error']\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(train_loss, label = 'TF_Model Training loss', color = 'darkgreen')\n",
    "plt.plot(test_loss, label = 'TF_Model Testing loss', color = 'lightgreen')\n",
    "plt.plot(train_rmse, label = 'TF_Model RMSE', color = 'Black')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_layer_names = True, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_es.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Training RMSE\n",
    "results_es.history['root_mean_squared_error'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Testing RMSE\n",
    "results_es.history['val_root_mean_squared_error'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any combination of hyperparameters. This model is overfit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eigth'></a>\n",
    "### Model 8: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline and gridsearch\n",
    "RandomForestRegressor().get_params().keys()\n",
    "pipe_rf = Pipeline([\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "pipe_rf_params = {'rf__max_depth': [5, 10, None],\n",
    "                 }\n",
    "pipe_rf.fit(Z_train_rf, y_train_rf)\n",
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid = pipe_rf_params,\n",
    "                     cv = 5)\n",
    "\n",
    "gs_rf.fit(Z_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best score rf: {gs_rf.best_score_}')\n",
    "print(f'Best parameters rf: {gs_rf.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstantiate pipe_svr with gridsearched parameters\n",
    "pipe_rf = Pipeline([\n",
    "    ('rf', RandomForestRegressor(max_depth = None))\n",
    "])\n",
    "pipe_rf = pipe_rf.fit(Z_train_mean, y_train_mean)\n",
    "\n",
    "rf_preds_train = gs_rf.predict(Z_train_rf)\n",
    "rf_preds_test = gs_rf.predict(Z_test_rf)\n",
    "\n",
    "print(f'Rf Training RMSE: {mean_squared_error(y_train_rf, rf_preds_train, squared = False)}')\n",
    "print(f'Rf Testing RMSE: {mean_squared_error(y_test_rf, rf_preds_test, squared = False)}')\n",
    "print(f'Rf Training R2: {pipe_rf.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Rf Testing R2: {pipe_rf.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ten strongest features for best testing model\n",
    "coefs_rf = pipe_rf.named_steps['rf'].feature_importances_\n",
    "model_zip = zip(feature_names_dummified, coefs_rf)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE does not beat linear regression for any combination of hyperparameters. This model is very overfit, but it is not close enough to production model to attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ninth'></a>\n",
    "### Model 9: PCA Pipeline w/ Lin Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline and gridsearch\n",
    "pipe_pca_lr = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('lr', LinearRegression()),\n",
    "])\n",
    "pipe_pca_lr_params = {'lr__normalize':[True, False],\n",
    "                  'lr__fit_intercept':[True, False],\n",
    "                  'pca__n_components':[5, 7, 10, 12, 15, 20, 30, 50],\n",
    "                  'pca__random_state':[42, 2021],\n",
    "                  'pca__tol':[0, 0.1, 1],\n",
    "                  'pca__whiten':[True, False],\n",
    "                  'pca__svd_solver':['auto','full', 'arpack','randomized'],\n",
    "                  'pca__iterated_power': [0, 1, 2, 3]\n",
    "                  }\n",
    "\n",
    "pipe_pca_lr.fit(Z_train_rf, y_train_rf)\n",
    "gs_pca_lr = GridSearchCV(pipe_pca_lr,\n",
    "                     param_grid = pipe_pca_lr_params,\n",
    "                     cv = 5)\n",
    "\n",
    "gs_pca_lr.fit(Z_train_rf, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best score rf: {gs_pca_lr.best_score_}')\n",
    "print(f'Best parameters rf: {gs_pca_lr.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstantiate pipe_svr with gridsearched parameters\n",
    "pipe_pca_lr = Pipeline([\n",
    "    ('pca', PCA(iterated_power = 1, n_components = 50, random_state = 2021, svd_solver = 'randomized', tol = 0, whiten = True)),\n",
    "    ('lr', LinearRegression(fit_intercept = True, normalize = True)),\n",
    "])\n",
    "pipe_pca_lr.fit(Z_train_rf, y_train_rf)\n",
    "\n",
    "lr_pca_preds_train = gs_pca_lr.predict(Z_train_rf)\n",
    "lr_pca_preds_test = gs_pca_lr.predict(Z_test_rf)\n",
    "\n",
    "print(f'Lr with PCA Training RMSE: {mean_squared_error(y_train_rf, lr_pca_preds_train, squared = False)}')\n",
    "print(f'Lr with Testing RMSE: {mean_squared_error(y_test_rf, lr_pca_preds_test, squared = False)}')\n",
    "print(f'Lr with PCA Training R2: {pipe_pca_lr.score(Z_train_rf, y_train_rf)}')\n",
    "print(f'Lr with with PCA Testing R2: {pipe_pca_lr.score(Z_test_rf, y_test_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show ten strongest features for best testing model\n",
    "coefs_pca_lr = pipe_pca_lr.named_steps['lr'].coef_.flatten()\n",
    "model_zip = zip(feature_names_dummified, coefs_pca_lr)\n",
    "model_zip_df = pd.DataFrame(model_zip, columns = ['features', 'coefficients'])\n",
    "model_zip_df.sort_values(by = 'coefficients', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is very close to the linear regression for the best hyperparameters and is well-fit, but is not worth the computational resources to use or further refine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
